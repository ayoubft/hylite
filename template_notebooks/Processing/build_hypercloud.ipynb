{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build hypercloud\n",
    "\n",
    "Load a directory of hyperspectral scenes that have defined camera orientation data (see pose estimation notebook). If calibration data is also defined (see identify calibration targets notebook) then an atmospheric and topographic correction will also be performed.\n",
    "\n",
    "The selected hypercloud derivatives are then calculated and exported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import utm\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hylite\n",
    "import hylite.io as io\n",
    "from hylite import HyScene\n",
    "from hylite.correct import ELC, Panel\n",
    "from hylite.reference.spectra import Target\n",
    "from hylite.correct.topography import sph2cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to point cloud hyperspectral data is being added to\n",
    "cloud_path = '/Users/thiele67/Documents/Data/CA/CA_50cm_coregistered.ply'\n",
    "export_directory = '/Users/thiele67/Documents/Data/CA/hypercloud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input directories (or images) to include in hypercloud\n",
    "path = [ \n",
    "    '/Users/thiele67/Documents/Data/CA/Terrestrial/2019',\n",
    "    ]\n",
    "\n",
    "image_paths = []\n",
    "for p in path:\n",
    "    if os.path.isdir(p):\n",
    "        image_paths += glob.glob( os.path.join(p,\"*.hdr\"), recursive=True )\n",
    "    else:\n",
    "        image_paths.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images:\n",
      "0 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2019/Corta_Atalaya__85_0m00_2m00_0079.hdr\n",
      "1 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2019/Corta_Atalaya__86_0m00_2m00_0080.hdr\n",
      "2 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2019/Corta_Atalaya__88_0m00_2m00_0082.hdr\n",
      "3 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2019/Corta_Atalaya__84_0m00_2m00_0078.hdr\n",
      "4 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2019/Corta_Atalaya__87_0m00_2m00_0081.hdr\n",
      "5 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2020/CA_0080__1_1m00_2m00.hdr\n",
      "6 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2020/CA_0079__0_0m00_1m00.hdr\n",
      "7 -  /Users/thiele67/Documents/Data/CA/Terrestrial/2020/CA_0082__3_3m00_4m00.hdr\n"
     ]
    }
   ],
   "source": [
    "print(\"Found %d images:\" % len(image_paths))\n",
    "for i, p in enumerate(image_paths):\n",
    "    print(\"%d - \" % i, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cloud export settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic projection settings\n",
    "occ_tol = 0 #occlusion tolerance (in same units as cloud). 0 disables occlusions. \n",
    "s = 3 # point size for projecting onto cloud. Must be an integer >= 1. \n",
    "\n",
    "#topographic correction settings\n",
    "topo_correct = 'ambient' #'cfac' #'cfac' # topographic correction method to apply. Set to None to disable. \n",
    "                         # 'ambient', 'cfac' or 'minnaert' normally give best results. \n",
    "high_thresh = 99 # pixels brighter than this percentile will be removed after the topo correction (removes false highlights)\n",
    "low_thresh = 0 # pixels darker than this percentile will be removed after the topo correction (uncorrected shadows)\n",
    "\n",
    "# atmospheric correction settings   \n",
    "atmos_correct = True # False # use target panels to apply atmospheric correction\n",
    "\n",
    "# colour correction settings\n",
    "colour_correct = True # perform colour correction\n",
    "reference_index = 0 # which image to use as reference for correction (match other images too)\n",
    "method = 'hist' # options are 'norm' (match mean and standard deviation) or 'hist' (match histograms)\n",
    "uniform = False # set to False to allow per-band colour correction (distorting the spectra).  \n",
    "\n",
    "#blending settings\n",
    "blend_mode = 'average' # options are \"average\",\n",
    "                       #  \"gsd\" (use pixel with smallest footprint),\n",
    "                       #  \"weighted\" (compute average weighted by gsd).\n",
    "            \n",
    "# export settings\n",
    "export_hypercloud = False # create a hypercloud?\n",
    "vis = hylite.RGB # which bands should be mapped to hypercloud RGB\n",
    "export_bands = (0,-1) # put in band wavelengths to export (e.g. 2000.0, 2500.0), or (0,-1) to export all bands. \n",
    "\n",
    "export_images = True # export corrected images? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run computer magics! â˜€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create HyScenes\n",
    "scenes = []\n",
    "cloud = io.loadCloudPLY(cloud_path)\n",
    "for i,p in enumerate(image_paths):\n",
    "    image = io.loadWithGDAL(p) # load image\n",
    "    cam = image.header.get_camera()\n",
    "    if cam is not None:\n",
    "        print(\"Building scene %d... \" % i, end='')\n",
    "        scenes.append( HyScene(  image, cloud, cam, occ_tol = occ_tol, s=s ) )\n",
    "    else:\n",
    "        print(\"Failed. Image has no camera pose (%s)\" % p)\n",
    "\n",
    "##############################################################\n",
    "# apply topographic and atmospheric corrections\n",
    "##############################################################\n",
    "uncorrected = [] # store scenes with no panel info here (we can calibrate them against corrected scenes [maybe])\n",
    "corrected = [] # scenes that have been successfully corrected\n",
    "for i,s in enumerate(scenes):\n",
    "    \n",
    "    print(\"Correcting scene %d...\" % i, end='')\n",
    "    \n",
    "    # correct scene!\n",
    "    suc = s.correct( atmos_correct, \n",
    "                     topo_correct is not None,\n",
    "                     method = topo_correct, \n",
    "                     low_thresh = low_thresh,\n",
    "                     high_thresh = high_thresh,\n",
    "                     vb = True,\n",
    "                     name = \"Scene %d\" % i, \n",
    "                     bands = vis,\n",
    "                     topo_kwds = {})\n",
    "    \n",
    "    if suc: # success - move on to next one\n",
    "        corrected.append(i)\n",
    "        print(\" Done.\")\n",
    "    else: # failed... why?\n",
    "        if len(s.image.header.get_panel_names()) == 0: # no calibration panel\n",
    "            uncorrected.append(i)\n",
    "            print(\" Missing panel.\")\n",
    "        elif not 'sun azimuth' in s.image.header: # no sun information for topo correction\n",
    "            print(\" Missing sun vector. Scene will not be corrected.\")\n",
    "            \n",
    "##############################################################\n",
    "#Try to match scenes with no panel against corrected scenes\n",
    "##############################################################\n",
    "max_points = 5000 # max number of pixels to calculate ELC for - make smaller to improve performance, \n",
    "                  # larger for better accuracy\n",
    "    \n",
    "for i in uncorrected:\n",
    "    \n",
    "    print(\"Matching scene %d... \" % i, end='')\n",
    "\n",
    "    overlap = []\n",
    "    overlap_size = []\n",
    "    for n in corrected:\n",
    "        px1, px2 = scenes[ i ].intersect_pixels( scenes[n] ) # get intersecting pixels\n",
    "        overlap_size.append( len(px1) )\n",
    "        overlap.append( (px1,px2) )\n",
    "\n",
    "    best = np.argmax( overlap_size )\n",
    "    if overlap_size[ best ] < 100:\n",
    "        print(\" insufficient overlap (%d pixels). Scene will not be corrected.\" % overlap_size[ best ])\n",
    "        assert False\n",
    "\n",
    "    print(\" found %d overlapping pixels.\" % overlap_size[ best ])\n",
    "\n",
    "    px1, px2 = overlap[best] # get overlapping pixels\n",
    "    best = corrected[best] # convert to index in list of all scenes\n",
    "\n",
    "    # subsample matches if too many points\n",
    "    if px1.shape[0] > max_points:\n",
    "        idx = np.random.choice( px1.shape[0], max_points, replace=False)\n",
    "        px1 = px1[idx,:]\n",
    "        px2 = px2[idx,:]\n",
    "\n",
    "    # create suite of ELC objects assuming each pixel is a calibration target\n",
    "    elc = []\n",
    "    for p in tqdm(range(px1.shape[0])):\n",
    "        rad = scenes[ i ].image.data[ px1[p,0], px1[p,1], : ]\n",
    "        refl = scenes[ best ].image.data[ px2[p,0], px2[p,1], : ]\n",
    "        t = Target( scenes[ best ].image.get_wavelengths(), refl, name=\"match\" )\n",
    "        elc.append( ELC( [ \n",
    "                    Panel( t, rad, wavelengths=scenes[ i ].image.get_wavelengths() )\n",
    "                        ] ) ) \n",
    "\n",
    "    # average slope/intercept of elc \n",
    "    vals = []\n",
    "    for e in elc:\n",
    "        vals.append( [e.slope, e.intercept])\n",
    "    vals = np.array(vals)\n",
    "    m,c = np.nanmedian( vals, axis=0 )\n",
    "\n",
    "    # create fake white reference and add to header\n",
    "    refl = np.full( len(scenes[ i ].image.get_wavelengths()), 1.0 ) # pure white\n",
    "    rad = (1 - c) / m\n",
    "    t = Target( scenes[ i ].image.get_wavelengths(), refl, name=\"white_estimate\")\n",
    "    p = Panel( t, rad, wavelengths = scenes[ i ].image.get_wavelengths() )\n",
    "    scenes[ i ].image.header.add_panel(p)\n",
    "\n",
    "    # plot it for reference\n",
    "    fig,ax = p.quick_plot()\n",
    "    ax.set_title(\"Scenes %d: estimated (pure) white panel radiance\" % i )\n",
    "    fig.show()\n",
    "    \n",
    "    # apply correction\n",
    "    print(\"Correcting scene %d...\" % i, end='')\n",
    "    \n",
    "    # correct scene!\n",
    "    s = scenes[i]\n",
    "    suc = s.correct( atmos_correct, \n",
    "                     topo_correct is not None,\n",
    "                     method = topo_correct, \n",
    "                     low_thresh = low_thresh,\n",
    "                     high_thresh = high_thresh,\n",
    "                     vb = True,\n",
    "                     name = \"Scene %d\" % i, \n",
    "                     bands = vis,\n",
    "                     topo_kwds = {})\n",
    "    \n",
    "    if suc: # success - move on to next one\n",
    "        print(\" Done.\")\n",
    "    else: # failed... why?\n",
    "        if len(s.image.header.get_panel_names()) == 0: # no calibration panel\n",
    "            print(\" Missing panel.\")\n",
    "        elif not 'sun azimuth' in s.image.header: # no sun information for topo correction\n",
    "            print(\" Missing sun vector. Scene will not be corrected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Apply colour corrections\n",
    "##############################################################\n",
    "if colour_correct:\n",
    "    for i,s in tqdm(enumerate(scenes), desc='Colour correction', total=len(scenes)):\n",
    "        if i == reference_index: \n",
    "            continue # skip reference image\n",
    "        s.match_colour_to( scenes[ reference_index ], method=method, uniform=uniform )\n",
    "        \n",
    "        # plot results\n",
    "        fig,ax = s.quick_plot(hylite.RGB)\n",
    "        ax.set_title(\"Colour corrected scene (RGB)\")\n",
    "        fig.show()\n",
    "        fig,ax = s.image.plot_spectra(band_range=export_bands)\n",
    "        ax.set_title(\"Colour corrected spectra\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_images: # export corrected image\n",
    "    for i, s in enumerate(scenes):\n",
    "        name = os.path.splitext(os.path.basename( image_paths[i] ))[0] + '_refl.hdr'\n",
    "        io.saveWithGDAL(os.path.join( export_directory, name ), s.image )\n",
    "        \n",
    "if export_hypercloud: # build and export hypercloud\n",
    "    hypercloud = HyScene.build_hypercloud( scenes, export_bands, blend_mode, trim=True, vb=True)\n",
    "    hypercloud.colorise( vis, stretch=(1,99) )\n",
    "    name = os.path.splitext(os.path.basename( image_paths[i] ))[0] + '_refl.hdr'\n",
    "    hypercloud.compress()\n",
    "    io.saveCloudPLY( os.path.join(export_directory, name), hypercloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
